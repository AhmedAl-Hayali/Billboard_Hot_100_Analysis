{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Billboard_Hot_100_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedAl-Hayali/Billboard_Hot_100_Analysis/blob/main/Billboard_Hot_100_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltEd1SbxsXnX"
      },
      "source": [
        "#~Imports~#\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import math\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "5FcGNExpsXnZ",
        "outputId": "86bf8399-426e-4515-b21c-e6c921a70fe8"
      },
      "source": [
        "#~Data Initialization~#\n",
        "\n",
        "# Original data set\n",
        "ogdf = pd.read_csv(\"Hot Stuff.csv\")\n",
        "# Making a copy of the original file for other sections in the notebook\n",
        "df =  ogdf.copy()\n",
        "#Reformat Date reading by pandas to match dataset (awkward because MM-DD-YY)\n",
        "df['WeekID'] = pd.to_datetime(df.WeekID)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0903d27ec824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Original data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mogdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hot Stuff.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Making a copy of the original file for other sections in the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mogdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Hot Stuff.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnuvbSewsXna"
      },
      "source": [
        "Work towards a regression analysis model that \n",
        "would allow me to track trends over time and\n",
        "trajectory of career, potential predictions\n",
        "about reason for a dip or increase, what\n",
        "could happen in the future?\n",
        "- Regression model to find curve of best fit for position over time\n",
        "- predict where song ends given where it starts and data from other songs from artist? from all artists?\n",
        "\n",
        "Outlier drops to optimize regression (look at artist_position('Spice Girls'))\n",
        "How to overlap these to see lifecycle of multiple artists over 1 time span?\n",
        "could secondary_y=True be useful for comparing two artists' stats?\\\n",
        "Insert index to count which hit this is (left of the song name, i.e. 1.Tim McGraw), i.e. first hit: #1 (i+1+': ',groups[i])\n",
        "\n",
        "Work on adding distribution graph for amount of songs on billboard over time\n",
        "\n",
        "- Next implementation: make figures and axis into objects to allow for oop and interpretation of multiple plots in the same figure, making comparisons ez\n",
        "- use cumsum/aggregate func to make an aggregate of data, giving points for each placement through 101-n, where n is position on billboard, visualize using box chart.\n",
        "\n",
        "Look into breaks for a data set and try out different charts *What could I use to represent the horizontal chart? It looks awkward top to bottom when our screens are wider than they are tall\n",
        "\n",
        "What would be a better way of visualizing this data other than splattering these dots on the screen? it gets messy with many songs\n",
        "\n",
        "Change background colour then work on the way the graphs look: https://stackoverflow.com/questions/14088687/how-to-change-plot-background-color"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2QLz5QLsXna"
      },
      "source": [
        "def artist_history(artist1, artist2=''):\n",
        "    stats1 = findArtist(df, 'Bruno Mars')\n",
        "    sortBy(stats1, 'WeekID').reset_index(drop=True)\n",
        "    stats1c = stats1.index.values\n",
        "    stats2 = df.loc[df['Performer']==artist2].sort_values(['WeekID'], ascending=True).reset_index(drop=True)\n",
        "    stats2c = stats2.index.values\n",
        "    height = (len(stats1['Song'].drop_duplicates())+len(stats2['Song'].drop_duplicates()))\n",
        "    fig1 = plt.figure(figsize = (5,.25*height)).gca().invert_yaxis()\n",
        "    plt.xticks(rotation=90)\n",
        "    ax1 = plt.axes()\n",
        "    ax2 = plt.axes()\n",
        "#     ax.plot(stats1['WeekID'],stats2['Song'],marker='o',c=marker_colors1,cmap='inferno')\n",
        "    marker_colors1 = [i/len(stats1c)*100 for i in stats1c]\n",
        "    ax1.scatter(stats1['WeekID'],stats1['Song'],marker='o',c=marker_colors1, cmap='inferno')\n",
        "    marker_colors2 = [i/len(stats2c)*100 for i in stats2c]\n",
        "    ax2.scatter(stats2['WeekID'],stats2['Song'],marker='o', c=marker_colors2, cmap='inferno')\n",
        "#     x= plt.scatter(stats1['WeekID'], stats1['Song'], marker='o',c=marker_colors1,cmap='inferno')\n",
        "#     y= plt.scatter(stats2['WeekID'], stats2['Song'], marker='bo', c=marker_colors2, cmap='inferno')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqb4ZreYsXnb"
      },
      "source": [
        "def findArtist(self, artist):\n",
        "    return self.loc[self['Performer']==artist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7UMCz-LsXnb"
      },
      "source": [
        "def sortBy(self, sortee):\n",
        "    return self.sort_values([sortee],ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQjKnyUqsXnb"
      },
      "source": [
        "artist_history('Bruno Mars')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnQldMVBsXnc"
      },
      "source": [
        "def artist_historyByGrouping(artist):\n",
        "    artist_stats = df.loc[df['Performer']==artist].sort_values(['WeekID'],ascending=True).reset_index(drop=True)\n",
        "    groups = artist_stats.groupby([\"Song\"], sort=False)\n",
        "    \n",
        "    plt.figure(figsize = (10,0.25*len(groups)))\n",
        "    for name, group in groups:\n",
        "        plt.plot(group[\"WeekID\"], group[\"Song\"], marker=\"o\", linestyle=\"\", label=name)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.xlabel(\"Week\")\n",
        "    plt.ylabel(\"Song\")\n",
        "    #plt.autoscale(enable = \"true\")\n",
        "    plt.title(artist+\" Song Chart\")\n",
        "    #plt.legend()\n",
        "    #Instead of doing this, we could create a timeline on the H-axis and put cumulative weeks on the dependent axis\n",
        "    #Start thinking of independent vs dependent axis, NOIR (nominal, ordinal, interval, ratio) data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESLPfM-isXnc"
      },
      "source": [
        "artist_historyByGrouping('Flo Rida')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3o3W11jsXnd"
      },
      "source": [
        "def artist_position(artist):\n",
        "    artistStats=df.loc[df['Performer']==artist].sort_values(['WeekID'], ascending=False).reset_index(drop=True)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.xticks(rotation=90)\n",
        "    grouped = artistStats.sort_values(['WeekID']).groupby(\"Song\",sort=False)\n",
        "    for song, songData in grouped:\n",
        "        plt.plot(songData[\"WeekID\"], songData[\"Week Position\"], marker=\"o\", linestyle=\"\",label=song)\n",
        "#     plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "#Segment to a set number of songs per chart to allow for clear visualization\n",
        "#Set the lower bound to be 1, top to be 100, then invert y axis :)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO4cxL58sXnd"
      },
      "source": [
        "artist_position('Taylor Swift')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "774zkXfhsXne"
      },
      "source": [
        "artist_position('Flo Rida')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39hD1bA7sXne"
      },
      "source": [
        "artist_history('Scatman John')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7hcNG9qqsXne"
      },
      "source": [
        "df2 = df.loc[df['Week Position']==1].reset_index(drop=True)\n",
        "df3 = df2.drop_duplicates(['SongID']).drop(columns=['url','SongID','Previous Week Position','Peak Position','Weeks on Chart']).sort_values('WeekID').reset_index(drop=True)\n",
        "df3['Year'] = pd.DatetimeIndex(df3['WeekID']).year\n",
        "wanted = 2015\n",
        "interval = 3\n",
        "df4 = df3.loc[(df3['Year']>=wanted) & (df3['Year']<(wanted+interval))]\n",
        "df4.head(64)\n",
        "\n",
        "#Add another column for weeks as #1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSNp7UhDsXnf"
      },
      "source": [
        "wanted = 2015\n",
        "interval = 5\n",
        "bgColor = '#E0FFFF'\n",
        "axisLabelTicksColor = '#D3D3D3'\n",
        "axisLabelColor = '#FFB6C1'\n",
        "\n",
        "df4 = df3.loc[(df3['Year']>=wanted) & (df3['Year']<(wanted+interval))]\n",
        "df4[\"SongNameW#\"] = df4.index.astype(str) + df4[\"Song\"]\n",
        "height = len(df4['Song'].drop_duplicates())\n",
        "fig = plt.figure(figsize = (5,.25*height)).gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.xticks(rotation=90)\n",
        "ax1 = plt.axes()\n",
        "ax1.set_xlabel(\"Date\", color= axisLabelColor)\n",
        "ax1.set_ylabel('Song', color = axisLabelColor)\n",
        "ax1.set_facecolor(bgColor)\n",
        "plt.setp(ax1.get_xticklabels(), color=axisLabelTicksColor)\n",
        "plt.setp(ax1.get_yticklabels(), color=axisLabelTicksColor)\n",
        "ax1.scatter(df4['WeekID'],df4['Song'],marker='o')\n",
        "\n",
        "#Create subplots to be able to compare turnover rate over time \n",
        "#Work on setting limits for this (this time to this time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjoGZOrNsXnf"
      },
      "source": [
        "df.drop_duplicates?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxaxNiV8sXng"
      },
      "source": [
        "def generic_cascade(songs, chart_title = 'Chart History', width = 10):\n",
        "    \"\"\"Creates cascading chart in the style of ARTIST HISTORY,\n",
        "        Given a dataframe of songs\n",
        "    \"\"\"\n",
        "    \n",
        "    #sorts songs by date\n",
        "    songs = songs.sort_values(['WeekID']).reset_index(drop=True)\n",
        "    \n",
        "    groups = songs.groupby([\"Song\"], sort=False) #Groups by song \n",
        "\n",
        "    fig = plt.figure(figsize = (width,0.25*len(groups))) #figure is longer if artist has more songs\n",
        "    \n",
        "    ax = plt.axes() #plot dat boy\n",
        "    \n",
        "    #plot for each song\n",
        "    for name, group in groups:\n",
        "        ax.plot(group[\"WeekID\"], group[\"Song\"], marker=\"o\", linestyle=\"\", label=name)\n",
        "    \n",
        "    \n",
        "    fig.autofmt_xdate() #date format\n",
        "    ax.invert_yaxis() #earlier songs at the top\n",
        "    ax.set(xlabel = 'Week', ylabel='Song', title = chart_title) #chart n stuff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn71e6l4sXng"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SMF-QQNsXnh"
      },
      "source": [
        "import datetime\n",
        "timeline = df.sort_values(['WeekID'])\n",
        "all_songs = timeline.groupby(['SongID'],sort=False)\n",
        "\n",
        "revival_songs = []\n",
        "for name, song in all_songs:\n",
        "    if not song[song['WeekID']>= song['WeekID'].iloc[0] + datetime.timedelta(days=365*5)].empty:\n",
        "        revival_songs.append(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MgVbpxdsXnh"
      },
      "source": [
        "artistStats.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5NJhUvysXnh"
      },
      "source": [
        "#sorts songs by date\n",
        "# songs = df.sort_values(['WeekID']).reset_index(drop=True)\n",
        "def artist_history()\n",
        "sns.set()\n",
        "artistStats1=df.loc[df['Performer'].str.contains('Adele')].sort_values(['WeekID'], ascending=False).reset_index(drop=True).drop(['url', 'SongID', 'Weeks on Chart'], axis=1)\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "ax = sns.scatterplot(data=artistStats1,x='WeekID',y='Week Position', hue='Song', legend = 'brief')\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles[::-1], labels[::-1], bbox_to_anchor=(1,1),loc='upper left',ncol=int(len(artistStats1.Song.drop_duplicates())/10))\n",
        "\n",
        "plt.xticks(rotation=-75)\n",
        "\n",
        "ax.set(xlim=(artistStats1.WeekID.min(),artistStats1.WeekID.max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jp98_lssXnh"
      },
      "source": [
        "def artist_history(artist,palt):\n",
        "    \"\"\"Creates a chart of an artists billboard hits, \n",
        "    Showing which songs were on the charts over time\"\"\"\n",
        "    \n",
        "    #data frame isolated for given artists music, sorted by date\n",
        "#     sns.color_palette(\"flare\", as_cmap=True)\n",
        "    sns.set() #style={darkgrid}\n",
        "#     st = axes_style('WhiteGrid')\n",
        "    \n",
        "#     axes_style(\"whitegrid\")\n",
        "    if ' ' not in artist:\n",
        "        artist_stats1 = df.loc[df.Performer.str.contains(artist)].loc[~df.Performer.str.contains(' ')].sort_values(['WeekID']).reset_index(drop=True)\n",
        "    else:\n",
        "        artist_stats1 = df.loc[df.Performer.str.contains(artist)].sort_values(['WeekID']).reset_index(drop=True)\n",
        "#     artist_stats1 = df.loc[df['Performer']==artist].sort_values(['WeekID']).reset_index(drop=True)\n",
        "    c = sns.color_palette(\"Set2\", len(artist_stats1.Song.drop_duplicates()))\n",
        "    \n",
        "    fig,ax = plt.subplots(figsize = (10,0.25*len(artist_stats1.Song.drop_duplicates()))) #figure is longer if artist has more songs\n",
        "    \n",
        "    ax1 = sns.scatterplot(data=artist_stats1,x='WeekID',y='Song', hue='Song', legend = 'brief', linewidth=0, palette = palt)\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "#     print('len h:',len(handles), 'len l:', len(labels))\n",
        "#     handles = handles.reverse().insert(0, None)\n",
        "#     labels = labels.reverse().insert(0, labels.pop())\n",
        "#     print('len h:',len(handles), 'len l:', len(labels))\n",
        "    ax1.legend(handles, labels, bbox_to_anchor=(1,1),loc='upper left',ncol=2)\n",
        "    #ncol = int(len(artist_stats1.Song.drop_duplicates())/15))\n",
        "\n",
        "    #     ax2 = sns.scatterplot(data=artist_stats2,x='WeekID',y='Song', hue='SongID', legend = False, linewidth=0)\n",
        "    plt.xticks(rotation=-75) #plot dat buoy\n",
        "    ax1.spines['left'].set_color('black')\n",
        "\n",
        "#     ax = sns.scatterplot(data=artist_stats1,x='WeekID',y='Week Position', hue='Song', legend = False)\n",
        "    \n",
        "    #plot for each song\n",
        "    #for name, group in groups:\n",
        "    #ax.plot(group[\"WeekID\"], group[\"Song\"], marker=\"o\", linestyle=\"\", label=name)\n",
        "    \n",
        "    \n",
        "#     fig.autofmt_xdate() #date format\n",
        "    ax1.invert_yaxis() #earlier songs at the top\n",
        "    ax1.set(xlabel = 'Week', ylabel='Song', title = artist+' Chart History', xlim=(artist_stats1.WeekID.min(),artist_stats1.WeekID.max())) #chart n stuff\n",
        "\n",
        "#     print(df.loc['Song'=='Controlla'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ekjjQNFwsXni"
      },
      "source": [
        "artist_history('Drake','Set1')\n",
        "#Idea: add parameter for palette colour :)\n",
        "#Add padding\n",
        "#Second idea: start documenting ur functions u ape\n",
        "#Add parameter for whether we want to consider spaces in name\n",
        "#Add parameter for start year of when we should look for songs, preset is boomer era\n",
        "#If instance1 = instance2mostrecent = 1, WeekID1 = WeekID2, WeeksOnChart1 < WeeksOnChart2, switch song 1 and 2, it should be from longest to shortest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z55TNomwsXnj"
      },
      "source": [
        "sns.set()\n",
        "g = sns.pairplot(df,vars={'WeekID','Week Position', 'Weeks on Chart', 'Previous Week Position'}, linewidth=0, hue='Song')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhi4-5fHsXno"
      },
      "source": [
        "sns.plotting_context?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmW5W20ssXno"
      },
      "source": [
        "slide the https://jakevdp.github.io/PythonDataScienceHandbook/04.14-visualization-with-seaborn.html into the code to "
      ]
    }
  ]
}